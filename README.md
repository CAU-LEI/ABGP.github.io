# ABGP软件说明书目录

1. [ABGP简介](#abgp简介)
2. [安装指南](#安装指南)
3. [功能介绍](#功能介绍)
    - [数据预处理](#数据预处理)
    - [特征工程](#特征工程)
    - [模型训练](#模型训练)
    - [模型评估](#模型评估)
    - [模型可解释性](#模型可解释性)
4. [参数介绍](#参数介绍)
5. [使用指南](#使用指南)
    - [快速入手](#快速入手)
    - [详细教程](#详细教程)
    - [示例说明](#示例说明)

## 1. ABGP简介

随着测序技术的发展和高通量基因型数据的产生，育种技术正由传统的“经验育种”逐步向“精准育种”转化。人工智能算法不需要预先的规则定义，通过数据和特征进行自主学习，擅长拟合数据中的非线性复杂关系，对于处理海量基因型数据更具有优势。将人工智能算法应用在基因组预测中，对于进一步提高重要表型育种值估计的准确性，加快遗传进展和育种进程具有重要意义。

Artificial Intelligence Breeding Pipeline(ABGP)是一款集特征选择、模型构建、速度优化、参数调节、位点可解释性于一体的AI育种软件，可以融合先验信息、场季效应、性别、批次等多种协变量信息，针对质量性状和数量性状，包含多种不同的AI算法模型，支持cpu、gpu计算的同时加入多进程、多线程、最优化迭代、网格搜索、麻雀搜索、SNP位点可解释性分析等模块。

整体具有以下特征：

1. 无需重算亲缘关系矩阵：ABGP通过直接使用特征数据进行训练和预测，避免了亲缘关系矩阵的计算和扩展问题。
2. 大幅降低内存消耗：通过优化数据处理和模型训练流程，ABGP显著降低了内存消耗。
3. 大幅提升预测速度：ABGP支持数据读取加速和GPU模型训练加速，在处理大规模数据时表现尤为出色。
4. 灵活性和适应性：机器学习方法可以处理不同类型的数据和任务，包括回归、分类以及具有复杂非线性关系的数据。这使得它们在处理复杂的基因组数据时更加灵活和高效。
5. 特征选择与重要性分析：机器学习模型可以自动进行特征选择，并通过SHAP（SHapley Additive exPlanations）等方法评估特征重要性，提供对预测结果的深入理解和解释。而GBLUP方法则主要依赖于线性假设，特征选择和重要性分析相对较弱。
6. 高性能和精度：通过使用先进的模型，可以显著提高预测的精度和性能。这些模型通过高效的梯度提升技术，能够在处理大规模数据和复杂模型时表现出色。
7. 自动化调参：机器学习软件集成了网格搜索和智能算法（如SSA）进行自动化调参，确保模型在不同数据集上的最佳表现。而GBLUP方法通常需要手动调参，效率较低。
8. 处理协变量：ABGP可以直接处理数据中的分类变量，自动进行编码和处理，而传统GBLUP方法在处理分类变量时较为复杂，需要额外的预处理步骤。

此外，ABGP还通过麻雀搜索等多种参数优化方法进一步提升预测准确性，可以根据SNP在模型中的权重挖掘与表型相关的SNP位点。通过多种方法评估SNP位点重要性，一般SNP位点的权重越大，与表型的相关性越强。此外，通过SHAP理论进行模型可解释性的输出，包括自定义选择特征位点进行重要性排序、基于单样本、多样本与特征结合进行局部和全局性交互解释，并进行可视化展示等。用户可自定义不同特征及样本之间的交互关系进行进一步研究。建议用户将ABGP不同方法提供的各SNP的权重与GWAS结果对比参考，排除各自方法中的假阳性结果，提高可信度。

ABGP在大数据时代，应对基因组数据分析需求方面展现了强大的优势，能够高效、准确地进行大规模数据的预测和分析。为AI育种提供了新的工具和软件平台。

## 2. 安装指南

### 克隆项目仓库

克隆项目的GitHub仓库到您的本地机器上。打开终端并执行以下命令：

```bash
git clone https://github.com/leiweiucas/ABGP
cd ABGP
```

### 创建虚拟环境
为确保依赖项之间没有冲突，建议使用虚拟环境。您可以使用 venv 或 conda 来创建虚拟环境。
使用 venv 创建虚拟环境：

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate  # Windows
```
### 使用 conda 创建虚拟环境：

```bash
conda create --name ABGP_env python=3.8
conda activate ABGP
```
### 安装依赖项
依赖项列在 requirements.txt 文件中。执行以下命令安装：

```bash
pip install -r requirements.txt
```
requirements.txt 中具体包版本为：

```bash
pandas==1.3.3
numpy==1.21.2
scipy==1.7.1
scikit-learn==0.24.2
matplotlib==3.4.3
catboost==1.0.4
lightgbm==3.2.1
phate==1.0.7
shap==0.39.0
joblib==1.1.0
```
plink安装
ABGP软件内置plink模块，下载plink软件后，在Linux或macOS上，编辑 ~/.bashrc 或 ~/.zshrc 文件：
```bash
export PATH=$PATH:/path/to/plink
```
在Windows上，通过系统属性中的“环境变量”选项进行配置。

## 3. 功能介绍

### 数据预处理
程序的预处理模块支持对输入的基因型数据的基因型频率(次等位基因频率)、基因型缺失率、样本缺失率进行统计并以直方图的形式展示并输出。方便用户了解数据整体情况，制定后续的研究方法。

表型文件预处理中，会判断表型值是否有缺失，如果有缺失，会将缺失值对应的行和基因型相对应的样本自动进行删除。并对表型值进行分布直方图的可视化。
3.2 特征工程
在基因型和表型数据的处理中，特征工程不仅可以有效减少数据维度，降低计算复杂度，还可以保留数据的主要信息。ABGP软件支持两种降维方法：PCA（主成分分析）和 PHATE（潜在拓扑保持嵌入）。

PCA（Principal Component Analysis，主成分分析）
PCA是一种常用的降维技术，通过正交变换将高维数据映射到低维空间，保留数据中的主要信息。PCA的主要优点是能够降低数据的维度，同时尽量保留数据的方差信息，从而简化模型的复杂度，提高计算效率。

PHATE（Potential of Heat-diffusion for Affinity-based Transition Embedding，潜在拓扑保持嵌入）
PHATE是一种最新的降维技术，它无需先验分布，使用梯度下降和矩阵分解技术来保留数据的潜在几何结构和拓扑特征，通过使用数据点之间的几何距离信息来捕获局部和全局非线性结构。PHATE被设计用来处理数据点之间嘈杂的非线性关系。PHATE生成一个低维表示，它在数据集中同时保留本地和全局结构，因此您可以根据数据集中出现的单元之间关系的图进而形成对数据结构的全局认识。

3.3 模型训练
本软件支持多种机器学习模型，适用于质量性状和数量性状的预测。其中，质量性状共包含10种不同的机器学习模型，数量性状共包含11种不同的机器学习模型。ABGP所包含的训练方法分为4类，包含基于特征距离的非线性方法、线性方法、bagging\boosting类算法，其中在数量性状中，非线性方法为knn和svm，线性方法为LinearRegressionRidge RegressionElasticNet bagging方法为RF，boosting类算法包括梯度提升树，xgboost，catboost，lightgbm和catboost。在质量性状中，非线性方法为knn和svm，线性方法为逻辑回归 bagging方法为RF，决策树算法。boosting类算法包括梯度提升树，xgboost，catboost，lightgbm和catboost。

用户可以根据具体需求选择合适的模型进行训练，并在训练过程中进行不同方法的参数优化以获得最佳性能。

3.4 模型评估
在ABGP中，对于质量性状，采用准确率作为评价。对于数量性状，采用预测值和真实值的皮尔逊相关系数作为评价标准。当使用交叉验证时，则采用教程验证的平均值作为准确性的评价标准。

3.5 模型可解释性
在机器学习模型中，解释模型的预测结果对于理解模型行为和建立信任至关重要。SHAP（SHapley Additive exPlanations）是一种基于博弈论的方法，用于解释模型的输出。它通过计算每个特征对预测结果的贡献，提供全局和局部的解释能力。ABGP软件集成了SHAP中的多种功能，用于分析和解释模型的特征及样本的重要性，以及对表型的贡献。

4. 参数介绍
以下为ABGP中所有参数汇总：
